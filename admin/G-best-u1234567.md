U6081614 (Tom Hamer):

Choosing my best class is difficult.

My default (because it works) would be the "HardPlayer" in the Board class which implements alpha beta to search the game tree. This AI beats
my two other AIs - the easy AI (one lookahead) and the medium AI (two lookaheads). However, it cheats and finds out which piece the player has next. This was not ideal, but it also was not appropriate
with the calculation time we had to have it scan every possible piece.

This was why I created two AI extensions.

a) IntelligentPlayer.java:

- Trained to find good moves using a one hidden layer neural network, the trained values are parsed in and put into a matrix
-
- See Trainer.java, Samples.txt and Board.play_n_sample
- play_n_sample was used to play lots and lots of games between two easy bots and print out the data
- the data was put into samples, where it was read in by trainer, put into a matrix, and a neural network was trained
- The neural network is in NN1HS.java
- It is entirely my own work and implementation of a java neural network. The backpropagation equations were taken from
Essentials of Statistical Machine learning by Trevor Hastey

Sadly, while the network is functioning, it did not work very well on the strato game data.
This appears to be due to a few reasons:

- The lack of convolutional layers meant that the network had to crunch a 27000 by 676 matrix as input. This meant that backpropogation
took a long time, and it made testing different learning rates, biases, and validation very slow and time consuming (it took about an hour to get one backpropagation step)
- Further, there is evidence to suggest that it could be impossible for a network without two hidden layers to learn Strato.
Playing chess seems to require two hidden layers, and in many ways the problem of strato is similar to chess (reference http://cs231n.stanford.edu/reports/ConvChess.pdf)
- A better implementation, if I had time I would have implemented the architecture Conv-relu affine*2, where there is a convolutional layer first
which reduces the training time, and a second fully connected layer to get more accurate high level reasoning.


b) MonteCarloPlayer.java
- Since the GO Monte Carlo method was so successful, and strato is a similar game to go, I decided to build a monte carlo tree
search algorithm
- the Monte Carlo algorithm is not particularly good as generating a random move is reletively intensive with our implementation.
- this means that the AI cannot play out enough games to make good estimates of what a good move actually is.
- a way this could be improved would be rather than generating all the moves, to generate a list of valid tiles from the baord state class
and guess random piece orientations until a valid move is found.
- That being said, it does beat a random player, especially at the end when the bot can easily tell whether a piece placement
leads to a win or a loss.


TO TRY DIFFERENT PLAY-OUTS BETWEEN EXPERIMENTAL PLAYERS USE THE FUNCTION "PLAY_N_SAMPLE" IN BOARD.JAVA (:

The results will log to the console. (Only the bots that work well and reliably are listed in the actual game as options)

I declare that this is entirely my own work, with the following documented exceptions:

The exceptions are mentioned above, except for LA4j, which is an external linear algebra package

Signed: Tom Hamer (U6081614)
